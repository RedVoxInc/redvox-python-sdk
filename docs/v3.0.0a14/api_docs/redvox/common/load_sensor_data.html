<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>redvox.common.load_sensor_data API documentation</title>
<meta name="description" content="This module loads or reads sensor data from various sources" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>redvox.common.load_sensor_data</code></h1>
</header>
<section id="section-intro">
<p>This module loads or reads sensor data from various sources</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module loads or reads sensor data from various sources
&#34;&#34;&#34;
import os
import glob
import numpy as np
import pandas as pd
from obspy import read
from typing import List, Dict, Optional
from redvox.api1000 import io as apim_io
from redvox.api900 import reader as api900_io
from redvox.common import file_statistics as fs, date_time_utils as dtu, timesync as ts
from redvox.common.sensor_data import SensorType, SensorData, Station, StationTiming, StationMetadata, DataPacket
from redvox.api1000.wrapped_redvox_packet.sensors.location import LocationProvider
from redvox.api1000.wrapped_redvox_packet.sensors import xyz, single
from redvox.api1000.wrapped_redvox_packet import wrapped_packet as apim_wp
from dataclasses import dataclass


@dataclass
class StationSummary:
    &#34;&#34;&#34;
    Contains a summary of each stations data read result.
    &#34;&#34;&#34;
    station_id: str
    station_uuid: str
    os: str
    os_version: str
    app_version: str
    audio_sampling_rate: float
    total_duration: float
    start_dt: dtu.datetime
    end_dt: dtu.datetime

    @staticmethod
    def from_station(station: Station) -&gt; &#39;StationSummary&#39;:
        total_duration: float = station.audio_sensor().data_duration_s()
        start_dt: dtu.datetime = dtu.datetime_from_epoch_microseconds_utc(station.audio_sensor().first_data_timestamp())
        end_dt: dtu.datetime = dtu.datetime_from_epoch_microseconds_utc(station.audio_sensor().last_data_timestamp())

        station_info = station.station_metadata
        audio = station.audio_sensor()
        return StationSummary(
            station_info.station_id,
            station_info.station_uuid,
            station_info.station_os if station_info.station_os is not None else &#34;OS UNKNOWN&#34;,
            station_info.station_os_version if station_info.station_os_version is not None else &#34;OS VERSION UNKNOWN&#34;,
            station_info.station_app_version if station_info.station_app_version is not None else &#34;APP VERSION UNKNOWN&#34;,
            audio.sample_rate if audio is not None else float(&#34;NaN&#34;),
            total_duration,
            start_dt,
            end_dt
        )


class ReadResult:
    &#34;&#34;&#34;
    Stores station information after being read from files
    &#34;&#34;&#34;
    def __init__(self,
                 station_id_uuid_to_stations: Dict[str, Station]):
        &#34;&#34;&#34;
        :param station_id_uuid_to_stations: station_id:station_uuid -&gt; station information
        &#34;&#34;&#34;
        self.station_id_uuid_to_stations: Dict[str, Station] = station_id_uuid_to_stations
        self.__station_id_to_id_uuid: Dict[str, str] = {}
        self.__station_summaries: List[StationSummary] = []

        self.update_metadata()

    def update_metadata(self):
        &#34;&#34;&#34;
        updates ids:uuids pairs and summary information
        &#34;&#34;&#34;
        for id_uuid, station in self.station_id_uuid_to_stations.items():
            s: List[str] = id_uuid.split(&#34;:&#34;)
            self.__station_id_to_id_uuid[s[0]] = s[1]
            self.__station_summaries.append(StationSummary.from_station(station))

    def __get_station_id_by_uuid(self, uuid: str) -&gt; str:
        &#34;&#34;&#34;
        given a uuid, returns the station_id
        :param uuid: uuid to search for
        :return: the station_id of the uuid, or an empty string if uuid doesn&#39;t exist
        &#34;&#34;&#34;
        for station_id, station_uuid in self.__station_id_to_id_uuid.items():
            if station_uuid == uuid:
                return station_id
        return &#34;&#34;

    def pop_station(self, station_id: str) -&gt; &#39;ReadResult&#39;:
        &#34;&#34;&#34;
        removes a station from the ReadResult; station_id can be one of id, uuid or id:uuid
        :param station_id: station to remove
        :return: copy of ReadResult without the station_id specified
        &#34;&#34;&#34;
        if &#34;:&#34; in station_id:
            s: List[str] = station_id.split(&#34;:&#34;)
            station_id = s[0]
        elif station_id in self.__station_id_to_id_uuid.values():  # check if uuid was given
            station_id = self.__get_station_id_by_uuid(station_id)
        if self.check_for_id(station_id):
            self.station_id_uuid_to_stations.pop(f&#34;{station_id}:{self.__station_id_to_id_uuid[station_id]}&#34;)
            self.__station_id_to_id_uuid.pop(station_id)
            summaries = self.__station_summaries.copy()  # put summaries into temp variable
            self.__station_summaries.clear()             # clear summaries and rebuild
            for summary in summaries:
                if summary.station_id != station_id:
                    self.__station_summaries.append(summary)
        else:
            print(f&#34;ReadResult cannot remove station {station_id} because it does not exist&#34;)
        return self

    def check_for_id(self, check_id: str) -&gt; bool:
        &#34;&#34;&#34;
        Look at keys and shortened keys in for the check_id; must be id or uuid combination
        :param check_id: id to look for
        :return: True if check_id is in the ReadResult
        &#34;&#34;&#34;
        return check_id in self.__station_id_to_id_uuid.keys() or check_id in self.__station_id_to_id_uuid.values()

    def get_station(self, station_id: str) -&gt; Optional[Station]:
        &#34;&#34;&#34;
        Find the station identified by the station_id given; it can be id or id:uuid
        :param station_id: str id of station; can be id or id:uuid
        :return: the station if it exists, None otherwise
        &#34;&#34;&#34;
        if &#34;:&#34; in station_id:
            return self.station_id_uuid_to_stations[station_id]
        elif self.check_for_id(station_id):
            return self.station_id_uuid_to_stations[f&#34;{station_id}:{self.__station_id_to_id_uuid[station_id]}&#34;]
        print(f&#34;WARNING: ReadResult attempted to read station id: {station_id}, but could not find id in results&#34;)
        return None

    def get_all_stations(self) -&gt; List[Station]:
        &#34;&#34;&#34;
        Return a list of all stations in the ReadResult
        :return: a list of all stations
        &#34;&#34;&#34;
        return list(self.station_id_uuid_to_stations.values())

    def get_station_summaries(self) -&gt; List[StationSummary]:
        &#34;&#34;&#34;
        :return: A list of StationSummaries contained in this ReadResult
        &#34;&#34;&#34;
        return self.__station_summaries

    def append_station(self, new_station_id: str, new_station: Station):
        &#34;&#34;&#34;
        adds a station to the ReadResult.  Appends data to existing stations
        :param new_station_id: id of station to add
        :param new_station: Station object to add
        &#34;&#34;&#34;
        if self.check_for_id(new_station_id):
            self.station_id_uuid_to_stations[new_station_id].append_station_data(new_station.station_data)
        else:
            self.station_id_uuid_to_stations[new_station_id] = new_station
            self.__station_id_to_id_uuid[new_station.station_metadata.station_id] = \
                new_station.station_metadata.station_uuid
            self.__station_summaries.append(StationSummary.from_station(new_station))

    def append(self, new_stations: &#39;ReadResult&#39;):
        &#34;&#34;&#34;
        adds stations to the ReadResult
        :param new_stations: stations to add
        &#34;&#34;&#34;
        for new_station_id, new_station in new_stations.station_id_uuid_to_stations.items():
            self.append_station(new_station_id, new_station)


def calc_evenly_sampled_timestamps(start: float, samples: int, rate_hz: float) -&gt; np.array:
    &#34;&#34;&#34;
    given a start time, calculates samples amount of evenly spaced timestamps at rate_hz
    :param start: float, start timestamp
    :param samples: int, number of samples
    :param rate_hz: float, sample rate in hz
    :return: np.array with evenly spaced timestamps starting at start
    &#34;&#34;&#34;
    return np.array(start + dtu.seconds_to_microseconds(np.arange(0, samples) / rate_hz))


def read_api900_non_mic_sensor(sensor: api900_io.RedvoxSensor, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that does not have mic data from an api900 data packet
    :param sensor: the non-mic api900 sensor to read
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.timestamps_microseconds_utc()
    if len(timestamps) &gt; 1:
        sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
    else:
        sample_interval = np.nan
    if type(sensor) in [api900_io.AccelerometerSensor, api900_io.MagnetometerSensor, api900_io.GyroscopeSensor]:
        data_for_df = np.transpose([timestamps,
                                    sensor.payload_values_x(), sensor.payload_values_y(), sensor.payload_values_z()])
        columns = [&#34;timestamps&#34;, f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    else:
        data_for_df = np.transpose([timestamps, sensor.payload_values()])
        columns = [&#34;timestamps&#34;, column_id]
    return SensorData(sensor.sensor_name(), pd.DataFrame(data_for_df, columns=columns), 1 / sample_interval,
                      sample_interval, False)


def read_api900_wrapped_packet(wrapped_packet: api900_io.WrappedRedvoxPacket) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api900 redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api900 redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    data_dict: Dict[SensorType, SensorData] = {}
    # there are 9 api900 sensors
    if wrapped_packet.has_microphone_sensor():
        sample_rate_hz = wrapped_packet.microphone_sensor().sample_rate_hz()
        timestamps = calc_evenly_sampled_timestamps(
            wrapped_packet.microphone_sensor().first_sample_timestamp_epoch_microseconds_utc(),
            fs.get_num_points_from_sample_rate(sample_rate_hz), sample_rate_hz)
        data_for_df = np.transpose([timestamps, wrapped_packet.microphone_sensor().payload_values().astype(float)])
        data_dict[SensorType.AUDIO] = SensorData(wrapped_packet.microphone_sensor().sensor_name(),
                                                 pd.DataFrame(data_for_df, columns=[&#34;timestamps&#34;, &#34;microphone&#34;]),
                                                 sample_rate_hz, 1 / sample_rate_hz, True)
    if wrapped_packet.has_accelerometer_sensor():
        data_dict[SensorType.ACCELEROMETER] = \
            read_api900_non_mic_sensor(wrapped_packet.accelerometer_sensor(), &#34;accelerometer&#34;)
    if wrapped_packet.has_magnetometer_sensor():
        data_dict[SensorType.MAGNETOMETER] = \
            read_api900_non_mic_sensor(wrapped_packet.magnetometer_sensor(), &#34;magnetometer&#34;)
    if wrapped_packet.has_gyroscope_sensor():
        data_dict[SensorType.GYROSCOPE] = read_api900_non_mic_sensor(wrapped_packet.gyroscope_sensor(), &#34;gyroscope&#34;)
    if wrapped_packet.has_barometer_sensor():
        data_dict[SensorType.PRESSURE] = read_api900_non_mic_sensor(wrapped_packet.barometer_sensor(), &#34;barometer&#34;)
    if wrapped_packet.has_light_sensor():
        data_dict[SensorType.LIGHT] = read_api900_non_mic_sensor(wrapped_packet.light_sensor(), &#34;light&#34;)
    if wrapped_packet.has_infrared_sensor():
        data_dict[SensorType.INFRARED] = read_api900_non_mic_sensor(wrapped_packet.infrared_sensor(), &#34;infrared&#34;)
    if wrapped_packet.has_image_sensor():
        data_dict[SensorType.IMAGE] = read_api900_non_mic_sensor(wrapped_packet.image_sensor(), &#34;image&#34;)
    if wrapped_packet.has_location_sensor():
        timestamps = wrapped_packet.location_sensor().timestamps_microseconds_utc()
        if len(timestamps) &gt; 1:
            sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
        else:
            sample_interval = np.nan
        if wrapped_packet.location_sensor().check_for_preset_lat_lon():
            lat_lon = wrapped_packet.location_sensor().get_payload_lat_lon()
            data_for_df = np.array([[timestamps[0], lat_lon[0], lat_lon[1], np.nan, np.nan, np.nan,
                                     LocationProvider.USER]])
        else:
            data_for_df = np.transpose([timestamps,
                                        wrapped_packet.location_sensor().payload_values_latitude(),
                                        wrapped_packet.location_sensor().payload_values_longitude(),
                                        wrapped_packet.location_sensor().payload_values_altitude(),
                                        wrapped_packet.location_sensor().payload_values_speed(),
                                        wrapped_packet.location_sensor().payload_values_accuracy(),
                                        np.full(len(timestamps), np.nan)])
        columns = [&#34;timestamps&#34;, &#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;accuracy&#34;, &#34;location_provider&#34;]
        data_dict[SensorType.LOCATION] = SensorData(wrapped_packet.location_sensor().sensor_name(),
                                                    pd.DataFrame(data_for_df, columns=columns),
                                                    1 / sample_interval, sample_interval, False)
    return data_dict


def load_station_from_api900(api900_packet: api900_io.WrappedRedvoxPacket,
                             start_timestamp_utc_s: Optional[int] = None,
                             end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single wrapped api900 packet
    :param api900_packet: wrapped api900 packet to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    # set station metadata and timing
    timing = StationTiming(api900_packet.mach_time_zero(), api900_packet.microphone_sensor().sample_rate_hz(),
                           api900_packet.app_file_start_timestamp_epoch_microseconds_utc(),
                           start_timestamp_utc_s, end_timestamp_utc_s,
                           np.nan if api900_packet.best_latency() is None else api900_packet.best_latency(),
                           0.0 if api900_packet.best_offset() is None else api900_packet.best_offset())
    metadata = StationMetadata(api900_packet.redvox_id(), api900_packet.device_make(),
                               api900_packet.device_model(), False, api900_packet.device_os(),
                               api900_packet.device_os_version(), &#34;Redvox&#34;, api900_packet.app_version(),
                               api900_packet.is_scrambled(), timing, station_uuid=api900_packet.uuid())
    data_dict = read_api900_wrapped_packet(api900_packet)
    packet_data = DataPacket(api900_packet.server_timestamp_epoch_microseconds_utc(),
                             api900_packet.app_file_start_timestamp_machine(),
                             len(api900_packet.microphone_sensor().payload_values()),
                             len(api900_packet.microphone_sensor().payload_values()) /
                             api900_packet.microphone_sensor().sample_rate_hz(),
                             float(api900_packet.start_timestamp_us_utc()), api900_packet.end_timestamp_us_utc(),
                             api900_packet.time_synchronization_sensor().payload_values(),
                             np.nan if api900_packet.best_latency() is None else api900_packet.best_latency(),
                             0.0 if api900_packet.best_offset() is None else api900_packet.best_offset())
    packet_list: List[DataPacket] = [packet_data]
    # get the best timing values for the station
    if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
        ts_analysis = ts.TimeSyncData(packet_data, metadata)
        timing.station_best_latency = ts_analysis.best_latency
        timing.station_best_offset = ts_analysis.best_offset
    return Station(metadata, data_dict, packet_list)


def load_station_from_api900_file(directory: str, start_timestamp_utc_s: Optional[int] = None,
                                  end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api900 file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    api900_packet = api900_io.read_rdvxz_file(directory)
    return load_station_from_api900(api900_packet, start_timestamp_utc_s, end_timestamp_utc_s)


def load_file_range_from_api900(directory: str,
                                start_timestamp_utc_s: Optional[int] = None,
                                end_timestamp_utc_s: Optional[int] = None,
                                redvox_ids: Optional[List[str]] = None,
                                structured_layout: bool = False,
                                concat_continuous_segments: bool = True) -&gt; ReadResult:
    &#34;&#34;&#34;
    reads in api900 data from a directory and returns a list of stations
    note that the param descriptions are taken directly from api900.reader.read_rdvxz_file_range
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxz files. If structured_layout is True, then this directory
                      must be the root api900 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against (default=[]).
    :param structured_layout: An optional value to define if this is loading structured data (default=False).
    :param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
                                       into multiple continuous rdvxz files separated at gaps.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: ReadResult = ReadResult({})
    all_data = api900_io.read_rdvxz_file_range(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                               structured_layout, concat_continuous_segments)
    for redvox_id, wrapped_packets in all_data.items():
        # set station metadata and timing based on first packet
        timing = StationTiming(wrapped_packets[0].mach_time_zero(),
                               wrapped_packets[0].microphone_sensor().sample_rate_hz(),
                               wrapped_packets[0].app_file_start_timestamp_epoch_microseconds_utc(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               np.nan if wrapped_packets[0].best_latency() is None else
                               wrapped_packets[0].best_latency(),
                               0.0 if wrapped_packets[0].best_offset() is None else wrapped_packets[0].best_offset())
        metadata = StationMetadata(wrapped_packets[0].redvox_id(), wrapped_packets[0].device_make(),
                                   wrapped_packets[0].device_model(), False, wrapped_packets[0].device_os(),
                                   wrapped_packets[0].device_os_version(), &#34;Redvox&#34;, wrapped_packets[0].app_version(),
                                   wrapped_packets[0].is_scrambled(), timing, station_uuid=wrapped_packets[0].uuid())
        # add data from packets
        new_station = Station(metadata)
        packet_list: List[DataPacket] = []
        for packet in wrapped_packets:
            if packet.has_time_synchronization_sensor():
                time_sync = packet.time_synchronization_sensor().payload_values()
            else:
                time_sync = None
            data_dict = read_api900_wrapped_packet(packet)
            new_station.append_station_data(data_dict)
            packet_data = DataPacket(packet.server_timestamp_epoch_microseconds_utc(),
                                     packet.app_file_start_timestamp_machine(),
                                     data_dict[SensorType.AUDIO].num_samples(),
                                     data_dict[SensorType.AUDIO].data_duration_s(),
                                     float(packet.start_timestamp_us_utc()), packet.end_timestamp_us_utc(),
                                     time_sync, np.nan if packet.best_latency() is None else packet.best_latency(),
                                     0.0 if packet.best_offset() is None else packet.best_offset())
            packet_list.append(packet_data)
        new_station.packet_data = packet_list

        if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
            # get the best timing values for the station
            ts_analysis = ts.TimeSyncAnalysis(new_station)
            new_station.station_metadata.timing_data.station_best_latency = ts_analysis.get_best_latency()
            new_station.station_metadata.timing_data.station_best_offset = ts_analysis.get_best_offset()

        # create the Station data object
        all_stations.append_station(redvox_id, new_station)

    return all_stations


def read_apim_xyz_sensor(sensor: xyz.Xyz, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has xyz data channels from an api M data packet
    :param sensor: the xyz api M sensor to read
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    if len(timestamps) &gt; 1:
        sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
    else:
        sample_interval = np.nan
    data_for_df = np.transpose([timestamps,
                                sensor.get_x_samples().get_values(),
                                sensor.get_y_samples().get_values(),
                                sensor.get_z_samples().get_values()])
    columns = [&#34;timestamps&#34;, f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, columns=columns),
                      1 / sample_interval, sample_interval, False)


def read_apim_single_sensor(sensor: single.Single, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has a single data channel from an api M data packet
    :param sensor: the single channel api M sensor to read
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    if len(timestamps) &gt; 1:
        sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
    else:
        sample_interval = np.nan
    data_for_df = np.transpose([timestamps, sensor.get_samples().get_values()])
    columns = [&#34;timestamps&#34;, column_id]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, columns=columns),
                      sample_interval, sample_interval, False)


def load_apim_wrapped_packet(wrapped_packet: apim_wp.WrappedRedvoxPacketM) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api M redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api M redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    data_dict: Dict[SensorType, SensorData] = {}
    sensors = wrapped_packet.get_sensors()
    # there are 16 api M sensors
    if sensors.has_audio() and sensors.validate_audio():
        sample_rate_hz = sensors.get_audio().get_sample_rate()
        data_for_df = sensors.get_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.AUDIO] = SensorData(sensors.get_audio().get_sensor_description(),
                                                 pd.DataFrame(np.transpose([timestamps, data_for_df]),
                                                              columns=[&#34;timestamps&#34;, &#34;microphone&#34;]),
                                                 sample_rate_hz, 1 / sample_rate_hz, True)
    if sensors.has_compress_audio() and sensors.validate_compressed_audio():
        sample_rate_hz = sensors.get_compressed_audio().get_sample_rate()
        data_for_df = sensors.get_compressed_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_compressed_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.COMPRESSED_AUDIO] = SensorData(sensors.get_compressed_audio().get_sensor_description(),
                                                            pd.DataFrame(np.transpose([timestamps, data_for_df]),
                                                                         columns=[&#34;compressed_audio&#34;]),
                                                            sample_rate_hz, 1 / sample_rate_hz, True)
    if sensors.has_accelerometer() and sensors.validate_accelerometer():
        data_dict[SensorType.ACCELEROMETER] = read_apim_xyz_sensor(sensors.get_accelerometer(), &#34;accelerometer&#34;)
    if sensors.has_magnetometer() and sensors.validate_magnetometer():
        data_dict[SensorType.MAGNETOMETER] = read_apim_xyz_sensor(sensors.get_magnetometer(), &#34;magnetometer&#34;)
    if sensors.has_linear_acceleration() and sensors.validate_accelerometer():
        data_dict[SensorType.LINEAR_ACCELERATION] = read_apim_xyz_sensor(sensors.get_linear_acceleration(),
                                                                         &#34;linear_accel&#34;)
    if sensors.has_orientation() and sensors.validate_orientation():
        data_dict[SensorType.ORIENTATION] = read_apim_xyz_sensor(sensors.get_orientation(), &#34;orientation&#34;)
    if sensors.has_rotation_vector() and sensors.validate_rotation_vector():
        data_dict[SensorType.ROTATION_VECTOR] = read_apim_xyz_sensor(sensors.get_rotation_vector(), &#34;rotation_vector&#34;)
    if sensors.has_gyroscope() and sensors.validate_gyroscope():
        data_dict[SensorType.GYROSCOPE] = read_apim_xyz_sensor(sensors.get_gyroscope(), &#34;gyroscope&#34;)
    if sensors.has_gravity() and sensors.validate_gravity():
        data_dict[SensorType.GRAVITY] = read_apim_xyz_sensor(sensors.get_gravity(), &#34;gravity&#34;)
    if sensors.has_pressure() and sensors.validate_pressure():
        data_dict[SensorType.PRESSURE] = read_apim_single_sensor(sensors.get_pressure(), &#34;barometer&#34;)
    if sensors.has_light() and sensors.validate_light():
        data_dict[SensorType.LIGHT] = read_apim_single_sensor(sensors.get_light(), &#34;light&#34;)
    if sensors.has_proximity() and sensors.validate_proximity():
        data_dict[SensorType.PROXIMITY] = read_apim_single_sensor(sensors.get_proximity(), &#34;proximity&#34;)
    if sensors.has_ambient_temperature() and sensors.validate_ambient_temperature():
        data_dict[SensorType.TEMPERATURE] = read_apim_single_sensor(sensors.get_ambient_temperature(), &#34;ambient_temp&#34;)
    if sensors.has_relative_humidity() and sensors.validate_relative_humidity():
        data_dict[SensorType.RELATIVE_HUMIDITY] = read_apim_single_sensor(sensors.get_relative_humidity(),
                                                                          &#34;rel_humidity&#34;)
    if sensors.has_image() and sensors.validate_image():
        timestamps = sensors.get_image().get_timestamps().get_timestamps()
        if len(timestamps) &gt; 1:
            sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
        else:
            sample_interval = np.nan
        data_for_df = np.transpose([timestamps, sensors.get_image().get_samples()])
        data_dict[SensorType.IMAGE] = SensorData(sensors.get_image().get_sensor_description(),
                                                 pd.DataFrame(data_for_df, columns=[&#34;image&#34;]),
                                                 1 / sample_interval, sample_interval, False)
    if sensors.has_location():
        if sensors.validate_location():
            timestamps = sensors.get_location().get_timestamps().get_timestamps()
            if len(timestamps) &gt; 1:
                sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
            else:
                sample_interval = np.nan
            data_for_df = np.transpose([timestamps,
                                        sensors.get_location().get_latitude_samples().get_values(),
                                        sensors.get_location().get_longitude_samples().get_values(),
                                        sensors.get_location().get_altitude_samples().get_values(),
                                        sensors.get_location().get_speed_samples().get_values(),
                                        sensors.get_location().get_bearing_samples().get_values(),
                                        sensors.get_location().get_horizontal_accuracy_samples().get_values(),
                                        sensors.get_location().get_vertical_accuracy_samples().get_values(),
                                        sensors.get_location().get_speed_samples().get_values(),
                                        sensors.get_location().get_bearing_accuracy_samples().get_values(),
                                        sensors.get_location().get_location_providers().get_values()])
        elif sensors.get_location().get_last_best_location():
            timestamps = [sensors.get_location().get_last_best_location().get_latitude_longitude_timestamp().get_mach()]
            sample_interval = np.nan
            data_for_df = np.transpose([[timestamps],
                                        [sensors.get_location().get_last_best_location().get_latitude()],
                                        [sensors.get_location().get_last_best_location().get_longitude()],
                                        [sensors.get_location().get_last_best_location().get_altitude()],
                                        [sensors.get_location().get_last_best_location().get_speed()],
                                        [sensors.get_location().get_last_best_location().get_bearing()],
                                        [sensors.get_location().get_last_best_location().get_horizontal_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_vertical_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_speed_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_bearing_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_location_provider()]])
        else:
            # well, there&#39;s no location, so there&#39;s nothing left to do but
            return data_dict
        # if here, location was good, add it in
        columns = [&#34;timestamps&#34;, &#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;bearing&#34;,
                   &#34;horizontal_accuracy&#34;, &#34;vertical_accuracy&#34;, &#34;speed_accuracy&#34;, &#34;bearing_accuracy&#34;,
                   &#34;location_provider&#34;]
        data_dict[SensorType.LOCATION] = SensorData(sensors.get_location().get_sensor_description(),
                                                    pd.DataFrame(data_for_df, columns=columns),
                                                    1 / sample_interval, sample_interval, False)
    return data_dict


def load_station_from_apim(directory: str, start_timestamp_utc_s: Optional[int] = None,
                           end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api M file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    read_packet = apim_io.read_rdvxm_file(directory)
    # set station metadata and timing based on first packet
    if read_packet.get_sensors().validate_audio():
        timing = StationTiming(read_packet.get_timing_information().get_app_start_mach_timestamp(),
                               read_packet.get_sensors().get_audio().get_sample_rate(),
                               read_packet.get_sensors().get_audio().get_first_sample_timestamp(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               np.nan if read_packet.get_timing_information().get_best_latency() is None else
                               read_packet.get_timing_information().get_best_latency(),
                               0.0 if read_packet.get_timing_information().get_best_offset() is None else
                               read_packet.get_timing_information().get_best_offset())
    else:
        raise ValueError(&#34;Station is missing Audio sensor!&#34;)
    metadata = StationMetadata(read_packet.get_station_information().get_id(),
                               read_packet.get_station_information().get_make(),
                               read_packet.get_station_information().get_model(), False,
                               read_packet.get_station_information().get_os().name,
                               read_packet.get_station_information().get_os_version(), &#34;Redvox&#34;,
                               read_packet.get_station_information().get_app_version(),
                               read_packet.get_station_information().get_app_settings().get_scramble_audio_data(),
                               timing, station_uuid=read_packet.get_station_information().get_uuid())
    # add data from packets
    time_sync_exchanges = read_packet.get_timing_information().get_synch_exchanges().get_values()
    time_sync = []
    for exchange in time_sync_exchanges:
        time_sync.extend([exchange.get_a1(), exchange.get_a2(), exchange.get_a3(),
                          exchange.get_b1(), exchange.get_b2(), exchange.get_b3()])
    data_dict = load_apim_wrapped_packet(read_packet)
    packet_data = DataPacket(read_packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                             read_packet.get_timing_information().get_app_start_mach_timestamp(),
                             data_dict[SensorType.AUDIO].num_samples(),
                             data_dict[SensorType.AUDIO].data_duration_s(),
                             read_packet.get_timing_information().get_packet_start_mach_timestamp(),
                             read_packet.get_timing_information().get_packet_end_mach_timestamp(),
                             np.array(time_sync),
                             np.nan if read_packet.get_timing_information().get_best_latency() is None else
                             read_packet.get_timing_information().get_best_latency(),
                             0.0 if read_packet.get_timing_information().get_best_offset() is None else
                             read_packet.get_timing_information().get_best_offset())
    packet_list: List[DataPacket] = [packet_data]
    # get the best timing values for the station
    if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
        ts_analysis = ts.TimeSyncData(packet_data, metadata)
        timing.station_best_latency = ts_analysis.best_latency
        timing.station_best_offset = ts_analysis.best_offset
    return Station(metadata, data_dict, packet_list)


def load_from_file_range_api_m(directory: str,
                               start_timestamp_utc_s: Optional[int] = None,
                               end_timestamp_utc_s: Optional[int] = None,
                               redvox_ids: Optional[List[str]] = None,
                               structured_layout: bool = False) -&gt; ReadResult:
    &#34;&#34;&#34;
    reads in api M data from a directory and returns a list of stations
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxm files. If structured_layout is True, then this directory
                      must be the root api1000 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp in seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp in seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: ReadResult = ReadResult({})
    all_data = apim_io.read_structured(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                       structured_layout)
    for read_packets in all_data.all_wrapped_packets:
        # set station metadata and timing based on first packet
        if read_packets.wrapped_packets[0]:
            if read_packets.wrapped_packets[0].get_sensors().get_audio():
                first_pack = read_packets.wrapped_packets[0]
                timing = StationTiming(read_packets.start_mach_timestamp, read_packets.audio_sample_rate,
                                       first_pack.get_sensors().get_audio().get_first_sample_timestamp(),
                                       start_timestamp_utc_s, end_timestamp_utc_s,
                                       np.nan if first_pack.get_timing_information().get_best_latency() is None else
                                       first_pack.get_timing_information().get_best_latency(),
                                       0.0 if first_pack.get_timing_information().get_best_offset() is None else
                                       first_pack.get_timing_information().get_best_offset())
                station_info = first_pack.get_station_information()
                metadata = StationMetadata(read_packets.redvox_id, station_info.get_make(), station_info.get_model(),
                                           False, station_info.get_os().name, station_info.get_os_version(),
                                           &#34;Redvox&#34;, station_info.get_app_version(),
                                           station_info.get_app_settings().get_scramble_audio_data(), timing,
                                           station_uuid=read_packets.uuid)
            else:
                raise ValueError(&#34;Error reading data window: Packet is missing Audio sensor!&#34;)
        else:
            raise ValueError(&#34;Error reading data window: First packet of data is missing!&#34;)
        new_station = Station(metadata)
        # add data from packets
        packet_list: List[DataPacket] = []
        for packet in read_packets.wrapped_packets:
            time_sync = packet.get_timing_information().get_synch_exchange_array()
            data_dict = load_apim_wrapped_packet(packet)
            new_station.append_station_data(data_dict)
            packet_data = DataPacket(packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                                     packet.get_timing_information().get_app_start_mach_timestamp(),
                                     data_dict[SensorType.AUDIO].num_samples(),
                                     data_dict[SensorType.AUDIO].data_duration_s(),
                                     packet.get_timing_information().get_packet_start_mach_timestamp(),
                                     packet.get_timing_information().get_packet_end_mach_timestamp(),
                                     np.array(time_sync),
                                     np.nan if packet.get_timing_information().get_best_latency() is None else
                                     packet.get_timing_information().get_best_latency(),
                                     0.0 if packet.get_timing_information().get_best_offset() is None else
                                     packet.get_timing_information().get_best_offset())
            packet_list.append(packet_data)
        new_station.packet_data = packet_list

        if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
            # get the best timing values for the station
            ts_analysis = ts.TimeSyncAnalysis(new_station)
            new_station.station_metadata.timing_data.station_best_latency = ts_analysis.get_best_latency()
            new_station.station_metadata.timing_data.station_best_offset = ts_analysis.get_best_offset()

        # create the Station data object
        all_stations.append_station(f&#34;{read_packets.redvox_id}:{read_packets.uuid}&#34;, new_station)
    return all_stations


def load_from_mseed(file_path: str, station_ids: Optional[List[str]] = None) -&gt; ReadResult:
    &#34;&#34;&#34;
    load station data from a miniseed file
    :param file_path: the location of the miniseed file
    :param station_ids: the station ids to search for, default None; if None, get all stations
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    stations: ReadResult = ReadResult({})
    strm = read(file_path)
    for data_stream in strm:
        record_info = data_stream.meta
        start_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;starttime&#34;].timestamp))
        end_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;endtime&#34;].timestamp))
        station_timing = StationTiming(np.nan, record_info[&#34;sampling_rate&#34;], start_time, start_time, end_time)
        station_id = f&#39;{record_info[&#34;network&#34;]}{record_info[&#34;station&#34;]}_{record_info[&#34;location&#34;]}&#39;
        metadata = StationMetadata(station_id, &#34;mb3_make&#34;, &#34;mb3_model&#34;, False, &#34;mb3_os&#34;, &#34;mb3_os_vers&#34;,
                                   &#34;mb3_recorder&#34;, &#34;mb3_recorder_version&#34;, False, station_timing,
                                   record_info[&#34;calib&#34;], record_info[&#34;network&#34;], record_info[&#34;station&#34;],
                                   record_info[&#34;location&#34;], record_info[&#34;channel&#34;], record_info[&#34;mseed&#34;][&#34;encoding&#34;])
        sample_rate_hz = record_info[&#34;sampling_rate&#34;]
        timestamps = calc_evenly_sampled_timestamps(start_time, int(record_info[&#34;npts&#34;]), sample_rate_hz)
        data_for_df = np.transpose([timestamps, data_stream.data])
        sensor_data = SensorData(record_info[&#34;channel&#34;], pd.DataFrame(data_for_df, columns=[&#34;timestamps&#34;, &#34;BDF&#34;]),
                                 record_info[&#34;sampling_rate&#34;], True)
        data_packet = DataPacket(np.nan, start_time, start_time, end_time)
        if station_ids is None or station_id in station_ids:
            stations.append_station(f&#34;{station_id}:{station_id}&#34;, Station(metadata, {SensorType.AUDIO: sensor_data},
                                                                          [data_packet]))
    return stations


def read_all_in_dir(directory: str,
                    start_timestamp_utc_s: Optional[int] = None,
                    end_timestamp_utc_s: Optional[int] = None,
                    redvox_ids: Optional[List[str]] = None,
                    structured_layout: bool = False) -&gt; ReadResult:
    &#34;&#34;&#34;
    load all data files in the directory
    :param directory: location of all the files; if structured_layout is True, the directory contains a root api1000,
                        api900, or mseed directory, if structured_layout is False, the directory contains unsorted files
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    # create the object to store the data
    stations: ReadResult = ReadResult({})
    # if structured_layout, there should be a specifically named folder in directory
    if structured_layout:
        if &#34;api900&#34; not in directory:
            api900_dir = os.path.join(directory, &#34;api900&#34;)
        else:
            api900_dir = directory
        if &#34;api1000&#34; not in directory:
            apim_dir = os.path.join(directory, &#34;api1000&#34;)
        else:
            apim_dir = directory
        if &#34;mseed&#34; not in directory:
            mseed_dir = os.path.join(directory, &#34;mseed&#34;)
        else:
            mseed_dir = directory
        # check if none of the paths exists
        if not (os.path.exists(api900_dir) or os.path.exists(apim_dir) or os.path.exists(mseed_dir)):
            # no specially named directory found; raise error
            raise ValueError(f&#34;{directory} does not contain api900, api1000 or mseed directory.&#34;)
    else:
        # load files from unstructured layout; everything is sitting in the main directory
        api900_dir = directory
        apim_dir = directory
        mseed_dir = directory

    # get api900 data
    stations.append(load_file_range_from_api900(api900_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                                redvox_ids, structured_layout, False))
    # get api1000 data
    stations.append(load_from_file_range_api_m(apim_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                               redvox_ids, structured_layout))
    # get mseed data
    all_paths = glob.glob(os.path.join(mseed_dir, &#34;*.mseed&#34;))
    for path in all_paths:
        stations.append(load_from_mseed(path, redvox_ids))
    return stations</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="redvox.common.load_sensor_data.calc_evenly_sampled_timestamps"><code class="name flex">
<span>def <span class="ident">calc_evenly_sampled_timestamps</span></span>(<span>start:float, samples:int, rate_hz:float) ><built-infunctionarray></span>
</code></dt>
<dd>
<div class="desc"><p>given a start time, calculates samples amount of evenly spaced timestamps at rate_hz
:param start: float, start timestamp
:param samples: int, number of samples
:param rate_hz: float, sample rate in hz
:return: np.array with evenly spaced timestamps starting at start</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_evenly_sampled_timestamps(start: float, samples: int, rate_hz: float) -&gt; np.array:
    &#34;&#34;&#34;
    given a start time, calculates samples amount of evenly spaced timestamps at rate_hz
    :param start: float, start timestamp
    :param samples: int, number of samples
    :param rate_hz: float, sample rate in hz
    :return: np.array with evenly spaced timestamps starting at start
    &#34;&#34;&#34;
    return np.array(start + dtu.seconds_to_microseconds(np.arange(0, samples) / rate_hz))</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_apim_wrapped_packet"><code class="name flex">
<span>def <span class="ident">load_apim_wrapped_packet</span></span>(<span>wrapped_packet:<a title="redvox.api1000.wrapped_redvox_packet.wrapped_packet.WrappedRedvoxPacketM" href="../api1000/wrapped_redvox_packet/wrapped_packet.html#redvox.api1000.wrapped_redvox_packet.wrapped_packet.WrappedRedvoxPacketM">WrappedRedvoxPacketM</a>) >typing.Dict[<a title="redvox.common.sensor_data.SensorType" href="sensor_data.html#redvox.common.sensor_data.SensorType">SensorType</a>,<a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>reads the data from a wrapped api M redvox packet into a dictionary of generic data
:param wrapped_packet: a wrapped api M redvox packet
:return: a dictionary containing all the sensor data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_apim_wrapped_packet(wrapped_packet: apim_wp.WrappedRedvoxPacketM) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api M redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api M redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    data_dict: Dict[SensorType, SensorData] = {}
    sensors = wrapped_packet.get_sensors()
    # there are 16 api M sensors
    if sensors.has_audio() and sensors.validate_audio():
        sample_rate_hz = sensors.get_audio().get_sample_rate()
        data_for_df = sensors.get_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.AUDIO] = SensorData(sensors.get_audio().get_sensor_description(),
                                                 pd.DataFrame(np.transpose([timestamps, data_for_df]),
                                                              columns=[&#34;timestamps&#34;, &#34;microphone&#34;]),
                                                 sample_rate_hz, 1 / sample_rate_hz, True)
    if sensors.has_compress_audio() and sensors.validate_compressed_audio():
        sample_rate_hz = sensors.get_compressed_audio().get_sample_rate()
        data_for_df = sensors.get_compressed_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_compressed_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.COMPRESSED_AUDIO] = SensorData(sensors.get_compressed_audio().get_sensor_description(),
                                                            pd.DataFrame(np.transpose([timestamps, data_for_df]),
                                                                         columns=[&#34;compressed_audio&#34;]),
                                                            sample_rate_hz, 1 / sample_rate_hz, True)
    if sensors.has_accelerometer() and sensors.validate_accelerometer():
        data_dict[SensorType.ACCELEROMETER] = read_apim_xyz_sensor(sensors.get_accelerometer(), &#34;accelerometer&#34;)
    if sensors.has_magnetometer() and sensors.validate_magnetometer():
        data_dict[SensorType.MAGNETOMETER] = read_apim_xyz_sensor(sensors.get_magnetometer(), &#34;magnetometer&#34;)
    if sensors.has_linear_acceleration() and sensors.validate_accelerometer():
        data_dict[SensorType.LINEAR_ACCELERATION] = read_apim_xyz_sensor(sensors.get_linear_acceleration(),
                                                                         &#34;linear_accel&#34;)
    if sensors.has_orientation() and sensors.validate_orientation():
        data_dict[SensorType.ORIENTATION] = read_apim_xyz_sensor(sensors.get_orientation(), &#34;orientation&#34;)
    if sensors.has_rotation_vector() and sensors.validate_rotation_vector():
        data_dict[SensorType.ROTATION_VECTOR] = read_apim_xyz_sensor(sensors.get_rotation_vector(), &#34;rotation_vector&#34;)
    if sensors.has_gyroscope() and sensors.validate_gyroscope():
        data_dict[SensorType.GYROSCOPE] = read_apim_xyz_sensor(sensors.get_gyroscope(), &#34;gyroscope&#34;)
    if sensors.has_gravity() and sensors.validate_gravity():
        data_dict[SensorType.GRAVITY] = read_apim_xyz_sensor(sensors.get_gravity(), &#34;gravity&#34;)
    if sensors.has_pressure() and sensors.validate_pressure():
        data_dict[SensorType.PRESSURE] = read_apim_single_sensor(sensors.get_pressure(), &#34;barometer&#34;)
    if sensors.has_light() and sensors.validate_light():
        data_dict[SensorType.LIGHT] = read_apim_single_sensor(sensors.get_light(), &#34;light&#34;)
    if sensors.has_proximity() and sensors.validate_proximity():
        data_dict[SensorType.PROXIMITY] = read_apim_single_sensor(sensors.get_proximity(), &#34;proximity&#34;)
    if sensors.has_ambient_temperature() and sensors.validate_ambient_temperature():
        data_dict[SensorType.TEMPERATURE] = read_apim_single_sensor(sensors.get_ambient_temperature(), &#34;ambient_temp&#34;)
    if sensors.has_relative_humidity() and sensors.validate_relative_humidity():
        data_dict[SensorType.RELATIVE_HUMIDITY] = read_apim_single_sensor(sensors.get_relative_humidity(),
                                                                          &#34;rel_humidity&#34;)
    if sensors.has_image() and sensors.validate_image():
        timestamps = sensors.get_image().get_timestamps().get_timestamps()
        if len(timestamps) &gt; 1:
            sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
        else:
            sample_interval = np.nan
        data_for_df = np.transpose([timestamps, sensors.get_image().get_samples()])
        data_dict[SensorType.IMAGE] = SensorData(sensors.get_image().get_sensor_description(),
                                                 pd.DataFrame(data_for_df, columns=[&#34;image&#34;]),
                                                 1 / sample_interval, sample_interval, False)
    if sensors.has_location():
        if sensors.validate_location():
            timestamps = sensors.get_location().get_timestamps().get_timestamps()
            if len(timestamps) &gt; 1:
                sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
            else:
                sample_interval = np.nan
            data_for_df = np.transpose([timestamps,
                                        sensors.get_location().get_latitude_samples().get_values(),
                                        sensors.get_location().get_longitude_samples().get_values(),
                                        sensors.get_location().get_altitude_samples().get_values(),
                                        sensors.get_location().get_speed_samples().get_values(),
                                        sensors.get_location().get_bearing_samples().get_values(),
                                        sensors.get_location().get_horizontal_accuracy_samples().get_values(),
                                        sensors.get_location().get_vertical_accuracy_samples().get_values(),
                                        sensors.get_location().get_speed_samples().get_values(),
                                        sensors.get_location().get_bearing_accuracy_samples().get_values(),
                                        sensors.get_location().get_location_providers().get_values()])
        elif sensors.get_location().get_last_best_location():
            timestamps = [sensors.get_location().get_last_best_location().get_latitude_longitude_timestamp().get_mach()]
            sample_interval = np.nan
            data_for_df = np.transpose([[timestamps],
                                        [sensors.get_location().get_last_best_location().get_latitude()],
                                        [sensors.get_location().get_last_best_location().get_longitude()],
                                        [sensors.get_location().get_last_best_location().get_altitude()],
                                        [sensors.get_location().get_last_best_location().get_speed()],
                                        [sensors.get_location().get_last_best_location().get_bearing()],
                                        [sensors.get_location().get_last_best_location().get_horizontal_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_vertical_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_speed_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_bearing_accuracy()],
                                        [sensors.get_location().get_last_best_location().get_location_provider()]])
        else:
            # well, there&#39;s no location, so there&#39;s nothing left to do but
            return data_dict
        # if here, location was good, add it in
        columns = [&#34;timestamps&#34;, &#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;bearing&#34;,
                   &#34;horizontal_accuracy&#34;, &#34;vertical_accuracy&#34;, &#34;speed_accuracy&#34;, &#34;bearing_accuracy&#34;,
                   &#34;location_provider&#34;]
        data_dict[SensorType.LOCATION] = SensorData(sensors.get_location().get_sensor_description(),
                                                    pd.DataFrame(data_for_df, columns=columns),
                                                    1 / sample_interval, sample_interval, False)
    return data_dict</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_file_range_from_api900"><code class="name flex">
<span>def <span class="ident">load_file_range_from_api900</span></span>(<span>directory:str, start_timestamp_utc_s:typing.Union[int,NoneType]=None, end_timestamp_utc_s:typing.Union[int,NoneType]=None, redvox_ids:typing.Union[typing.List[str],NoneType]=None, structured_layout:bool=False, concat_continuous_segments:bool=True) ><a title="redvox.common.load_sensor_data.ReadResult" href="#redvox.common.load_sensor_data.ReadResult">ReadResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>reads in api900 data from a directory and returns a list of stations
note that the param descriptions are taken directly from api900.reader.read_rdvxz_file_range
:param directory: The root directory of the data. If structured_layout is False, then this directory will
contain various unorganized .rdvxz files. If structured_layout is True, then this directory
must be the root api900 directory of the structured files.
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:param redvox_ids: An optional list of redvox_ids to filter against (default=[]).
:param structured_layout: An optional value to define if this is loading structured data (default=False).
:param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
into multiple continuous rdvxz files separated at gaps.
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_file_range_from_api900(directory: str,
                                start_timestamp_utc_s: Optional[int] = None,
                                end_timestamp_utc_s: Optional[int] = None,
                                redvox_ids: Optional[List[str]] = None,
                                structured_layout: bool = False,
                                concat_continuous_segments: bool = True) -&gt; ReadResult:
    &#34;&#34;&#34;
    reads in api900 data from a directory and returns a list of stations
    note that the param descriptions are taken directly from api900.reader.read_rdvxz_file_range
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxz files. If structured_layout is True, then this directory
                      must be the root api900 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against (default=[]).
    :param structured_layout: An optional value to define if this is loading structured data (default=False).
    :param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
                                       into multiple continuous rdvxz files separated at gaps.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: ReadResult = ReadResult({})
    all_data = api900_io.read_rdvxz_file_range(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                               structured_layout, concat_continuous_segments)
    for redvox_id, wrapped_packets in all_data.items():
        # set station metadata and timing based on first packet
        timing = StationTiming(wrapped_packets[0].mach_time_zero(),
                               wrapped_packets[0].microphone_sensor().sample_rate_hz(),
                               wrapped_packets[0].app_file_start_timestamp_epoch_microseconds_utc(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               np.nan if wrapped_packets[0].best_latency() is None else
                               wrapped_packets[0].best_latency(),
                               0.0 if wrapped_packets[0].best_offset() is None else wrapped_packets[0].best_offset())
        metadata = StationMetadata(wrapped_packets[0].redvox_id(), wrapped_packets[0].device_make(),
                                   wrapped_packets[0].device_model(), False, wrapped_packets[0].device_os(),
                                   wrapped_packets[0].device_os_version(), &#34;Redvox&#34;, wrapped_packets[0].app_version(),
                                   wrapped_packets[0].is_scrambled(), timing, station_uuid=wrapped_packets[0].uuid())
        # add data from packets
        new_station = Station(metadata)
        packet_list: List[DataPacket] = []
        for packet in wrapped_packets:
            if packet.has_time_synchronization_sensor():
                time_sync = packet.time_synchronization_sensor().payload_values()
            else:
                time_sync = None
            data_dict = read_api900_wrapped_packet(packet)
            new_station.append_station_data(data_dict)
            packet_data = DataPacket(packet.server_timestamp_epoch_microseconds_utc(),
                                     packet.app_file_start_timestamp_machine(),
                                     data_dict[SensorType.AUDIO].num_samples(),
                                     data_dict[SensorType.AUDIO].data_duration_s(),
                                     float(packet.start_timestamp_us_utc()), packet.end_timestamp_us_utc(),
                                     time_sync, np.nan if packet.best_latency() is None else packet.best_latency(),
                                     0.0 if packet.best_offset() is None else packet.best_offset())
            packet_list.append(packet_data)
        new_station.packet_data = packet_list

        if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
            # get the best timing values for the station
            ts_analysis = ts.TimeSyncAnalysis(new_station)
            new_station.station_metadata.timing_data.station_best_latency = ts_analysis.get_best_latency()
            new_station.station_metadata.timing_data.station_best_offset = ts_analysis.get_best_offset()

        # create the Station data object
        all_stations.append_station(redvox_id, new_station)

    return all_stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_from_file_range_api_m"><code class="name flex">
<span>def <span class="ident">load_from_file_range_api_m</span></span>(<span>directory:str, start_timestamp_utc_s:typing.Union[int,NoneType]=None, end_timestamp_utc_s:typing.Union[int,NoneType]=None, redvox_ids:typing.Union[typing.List[str],NoneType]=None, structured_layout:bool=False) ><a title="redvox.common.load_sensor_data.ReadResult" href="#redvox.common.load_sensor_data.ReadResult">ReadResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>reads in api M data from a directory and returns a list of stations
:param directory: The root directory of the data. If structured_layout is False, then this directory will
contain various unorganized .rdvxm files. If structured_layout is True, then this directory
must be the root api1000 directory of the structured files.
:param start_timestamp_utc_s: The start timestamp in seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp in seconds since the epoch UTC.
:param redvox_ids: An optional list of redvox_ids to filter against, default empty list
:param structured_layout: An optional value to define if this is loading structured data, default False.
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_from_file_range_api_m(directory: str,
                               start_timestamp_utc_s: Optional[int] = None,
                               end_timestamp_utc_s: Optional[int] = None,
                               redvox_ids: Optional[List[str]] = None,
                               structured_layout: bool = False) -&gt; ReadResult:
    &#34;&#34;&#34;
    reads in api M data from a directory and returns a list of stations
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxm files. If structured_layout is True, then this directory
                      must be the root api1000 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp in seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp in seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: ReadResult = ReadResult({})
    all_data = apim_io.read_structured(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                       structured_layout)
    for read_packets in all_data.all_wrapped_packets:
        # set station metadata and timing based on first packet
        if read_packets.wrapped_packets[0]:
            if read_packets.wrapped_packets[0].get_sensors().get_audio():
                first_pack = read_packets.wrapped_packets[0]
                timing = StationTiming(read_packets.start_mach_timestamp, read_packets.audio_sample_rate,
                                       first_pack.get_sensors().get_audio().get_first_sample_timestamp(),
                                       start_timestamp_utc_s, end_timestamp_utc_s,
                                       np.nan if first_pack.get_timing_information().get_best_latency() is None else
                                       first_pack.get_timing_information().get_best_latency(),
                                       0.0 if first_pack.get_timing_information().get_best_offset() is None else
                                       first_pack.get_timing_information().get_best_offset())
                station_info = first_pack.get_station_information()
                metadata = StationMetadata(read_packets.redvox_id, station_info.get_make(), station_info.get_model(),
                                           False, station_info.get_os().name, station_info.get_os_version(),
                                           &#34;Redvox&#34;, station_info.get_app_version(),
                                           station_info.get_app_settings().get_scramble_audio_data(), timing,
                                           station_uuid=read_packets.uuid)
            else:
                raise ValueError(&#34;Error reading data window: Packet is missing Audio sensor!&#34;)
        else:
            raise ValueError(&#34;Error reading data window: First packet of data is missing!&#34;)
        new_station = Station(metadata)
        # add data from packets
        packet_list: List[DataPacket] = []
        for packet in read_packets.wrapped_packets:
            time_sync = packet.get_timing_information().get_synch_exchange_array()
            data_dict = load_apim_wrapped_packet(packet)
            new_station.append_station_data(data_dict)
            packet_data = DataPacket(packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                                     packet.get_timing_information().get_app_start_mach_timestamp(),
                                     data_dict[SensorType.AUDIO].num_samples(),
                                     data_dict[SensorType.AUDIO].data_duration_s(),
                                     packet.get_timing_information().get_packet_start_mach_timestamp(),
                                     packet.get_timing_information().get_packet_end_mach_timestamp(),
                                     np.array(time_sync),
                                     np.nan if packet.get_timing_information().get_best_latency() is None else
                                     packet.get_timing_information().get_best_latency(),
                                     0.0 if packet.get_timing_information().get_best_offset() is None else
                                     packet.get_timing_information().get_best_offset())
            packet_list.append(packet_data)
        new_station.packet_data = packet_list

        if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
            # get the best timing values for the station
            ts_analysis = ts.TimeSyncAnalysis(new_station)
            new_station.station_metadata.timing_data.station_best_latency = ts_analysis.get_best_latency()
            new_station.station_metadata.timing_data.station_best_offset = ts_analysis.get_best_offset()

        # create the Station data object
        all_stations.append_station(f&#34;{read_packets.redvox_id}:{read_packets.uuid}&#34;, new_station)
    return all_stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_from_mseed"><code class="name flex">
<span>def <span class="ident">load_from_mseed</span></span>(<span>file_path:str, station_ids:typing.Union[typing.List[str],NoneType]=None) ><a title="redvox.common.load_sensor_data.ReadResult" href="#redvox.common.load_sensor_data.ReadResult">ReadResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>load station data from a miniseed file
:param file_path: the location of the miniseed file
:param station_ids: the station ids to search for, default None; if None, get all stations
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_from_mseed(file_path: str, station_ids: Optional[List[str]] = None) -&gt; ReadResult:
    &#34;&#34;&#34;
    load station data from a miniseed file
    :param file_path: the location of the miniseed file
    :param station_ids: the station ids to search for, default None; if None, get all stations
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    stations: ReadResult = ReadResult({})
    strm = read(file_path)
    for data_stream in strm:
        record_info = data_stream.meta
        start_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;starttime&#34;].timestamp))
        end_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;endtime&#34;].timestamp))
        station_timing = StationTiming(np.nan, record_info[&#34;sampling_rate&#34;], start_time, start_time, end_time)
        station_id = f&#39;{record_info[&#34;network&#34;]}{record_info[&#34;station&#34;]}_{record_info[&#34;location&#34;]}&#39;
        metadata = StationMetadata(station_id, &#34;mb3_make&#34;, &#34;mb3_model&#34;, False, &#34;mb3_os&#34;, &#34;mb3_os_vers&#34;,
                                   &#34;mb3_recorder&#34;, &#34;mb3_recorder_version&#34;, False, station_timing,
                                   record_info[&#34;calib&#34;], record_info[&#34;network&#34;], record_info[&#34;station&#34;],
                                   record_info[&#34;location&#34;], record_info[&#34;channel&#34;], record_info[&#34;mseed&#34;][&#34;encoding&#34;])
        sample_rate_hz = record_info[&#34;sampling_rate&#34;]
        timestamps = calc_evenly_sampled_timestamps(start_time, int(record_info[&#34;npts&#34;]), sample_rate_hz)
        data_for_df = np.transpose([timestamps, data_stream.data])
        sensor_data = SensorData(record_info[&#34;channel&#34;], pd.DataFrame(data_for_df, columns=[&#34;timestamps&#34;, &#34;BDF&#34;]),
                                 record_info[&#34;sampling_rate&#34;], True)
        data_packet = DataPacket(np.nan, start_time, start_time, end_time)
        if station_ids is None or station_id in station_ids:
            stations.append_station(f&#34;{station_id}:{station_id}&#34;, Station(metadata, {SensorType.AUDIO: sensor_data},
                                                                          [data_packet]))
    return stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_station_from_api900"><code class="name flex">
<span>def <span class="ident">load_station_from_api900</span></span>(<span>api900_packet:<a title="redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket" href="../api900/wrapped_redvox_packet.html#redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket">WrappedRedvoxPacket</a>, start_timestamp_utc_s:typing.Union[int,NoneType]=None, end_timestamp_utc_s:typing.Union[int,NoneType]=None) ><a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a></span>
</code></dt>
<dd>
<div class="desc"><p>reads in station data from a single wrapped api900 packet
:param api900_packet: wrapped api900 packet to read from
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:return: a station Object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_station_from_api900(api900_packet: api900_io.WrappedRedvoxPacket,
                             start_timestamp_utc_s: Optional[int] = None,
                             end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single wrapped api900 packet
    :param api900_packet: wrapped api900 packet to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    # set station metadata and timing
    timing = StationTiming(api900_packet.mach_time_zero(), api900_packet.microphone_sensor().sample_rate_hz(),
                           api900_packet.app_file_start_timestamp_epoch_microseconds_utc(),
                           start_timestamp_utc_s, end_timestamp_utc_s,
                           np.nan if api900_packet.best_latency() is None else api900_packet.best_latency(),
                           0.0 if api900_packet.best_offset() is None else api900_packet.best_offset())
    metadata = StationMetadata(api900_packet.redvox_id(), api900_packet.device_make(),
                               api900_packet.device_model(), False, api900_packet.device_os(),
                               api900_packet.device_os_version(), &#34;Redvox&#34;, api900_packet.app_version(),
                               api900_packet.is_scrambled(), timing, station_uuid=api900_packet.uuid())
    data_dict = read_api900_wrapped_packet(api900_packet)
    packet_data = DataPacket(api900_packet.server_timestamp_epoch_microseconds_utc(),
                             api900_packet.app_file_start_timestamp_machine(),
                             len(api900_packet.microphone_sensor().payload_values()),
                             len(api900_packet.microphone_sensor().payload_values()) /
                             api900_packet.microphone_sensor().sample_rate_hz(),
                             float(api900_packet.start_timestamp_us_utc()), api900_packet.end_timestamp_us_utc(),
                             api900_packet.time_synchronization_sensor().payload_values(),
                             np.nan if api900_packet.best_latency() is None else api900_packet.best_latency(),
                             0.0 if api900_packet.best_offset() is None else api900_packet.best_offset())
    packet_list: List[DataPacket] = [packet_data]
    # get the best timing values for the station
    if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
        ts_analysis = ts.TimeSyncData(packet_data, metadata)
        timing.station_best_latency = ts_analysis.best_latency
        timing.station_best_offset = ts_analysis.best_offset
    return Station(metadata, data_dict, packet_list)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_station_from_api900_file"><code class="name flex">
<span>def <span class="ident">load_station_from_api900_file</span></span>(<span>directory:str, start_timestamp_utc_s:typing.Union[int,NoneType]=None, end_timestamp_utc_s:typing.Union[int,NoneType]=None) ><a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a></span>
</code></dt>
<dd>
<div class="desc"><p>reads in station data from a single api900 file
:param directory: string of the file to read from
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:return: a station Object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_station_from_api900_file(directory: str, start_timestamp_utc_s: Optional[int] = None,
                                  end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api900 file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    api900_packet = api900_io.read_rdvxz_file(directory)
    return load_station_from_api900(api900_packet, start_timestamp_utc_s, end_timestamp_utc_s)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_station_from_apim"><code class="name flex">
<span>def <span class="ident">load_station_from_apim</span></span>(<span>directory:str, start_timestamp_utc_s:typing.Union[int,NoneType]=None, end_timestamp_utc_s:typing.Union[int,NoneType]=None) ><a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a></span>
</code></dt>
<dd>
<div class="desc"><p>reads in station data from a single api M file
:param directory: string of the file to read from
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:return: a station Object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_station_from_apim(directory: str, start_timestamp_utc_s: Optional[int] = None,
                           end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api M file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    read_packet = apim_io.read_rdvxm_file(directory)
    # set station metadata and timing based on first packet
    if read_packet.get_sensors().validate_audio():
        timing = StationTiming(read_packet.get_timing_information().get_app_start_mach_timestamp(),
                               read_packet.get_sensors().get_audio().get_sample_rate(),
                               read_packet.get_sensors().get_audio().get_first_sample_timestamp(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               np.nan if read_packet.get_timing_information().get_best_latency() is None else
                               read_packet.get_timing_information().get_best_latency(),
                               0.0 if read_packet.get_timing_information().get_best_offset() is None else
                               read_packet.get_timing_information().get_best_offset())
    else:
        raise ValueError(&#34;Station is missing Audio sensor!&#34;)
    metadata = StationMetadata(read_packet.get_station_information().get_id(),
                               read_packet.get_station_information().get_make(),
                               read_packet.get_station_information().get_model(), False,
                               read_packet.get_station_information().get_os().name,
                               read_packet.get_station_information().get_os_version(), &#34;Redvox&#34;,
                               read_packet.get_station_information().get_app_version(),
                               read_packet.get_station_information().get_app_settings().get_scramble_audio_data(),
                               timing, station_uuid=read_packet.get_station_information().get_uuid())
    # add data from packets
    time_sync_exchanges = read_packet.get_timing_information().get_synch_exchanges().get_values()
    time_sync = []
    for exchange in time_sync_exchanges:
        time_sync.extend([exchange.get_a1(), exchange.get_a2(), exchange.get_a3(),
                          exchange.get_b1(), exchange.get_b2(), exchange.get_b3()])
    data_dict = load_apim_wrapped_packet(read_packet)
    packet_data = DataPacket(read_packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                             read_packet.get_timing_information().get_app_start_mach_timestamp(),
                             data_dict[SensorType.AUDIO].num_samples(),
                             data_dict[SensorType.AUDIO].data_duration_s(),
                             read_packet.get_timing_information().get_packet_start_mach_timestamp(),
                             read_packet.get_timing_information().get_packet_end_mach_timestamp(),
                             np.array(time_sync),
                             np.nan if read_packet.get_timing_information().get_best_latency() is None else
                             read_packet.get_timing_information().get_best_latency(),
                             0.0 if read_packet.get_timing_information().get_best_offset() is None else
                             read_packet.get_timing_information().get_best_offset())
    packet_list: List[DataPacket] = [packet_data]
    # get the best timing values for the station
    if timing.station_best_latency is None or np.isnan(timing.station_best_latency):
        ts_analysis = ts.TimeSyncData(packet_data, metadata)
        timing.station_best_latency = ts_analysis.best_latency
        timing.station_best_offset = ts_analysis.best_offset
    return Station(metadata, data_dict, packet_list)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_all_in_dir"><code class="name flex">
<span>def <span class="ident">read_all_in_dir</span></span>(<span>directory:str, start_timestamp_utc_s:typing.Union[int,NoneType]=None, end_timestamp_utc_s:typing.Union[int,NoneType]=None, redvox_ids:typing.Union[typing.List[str],NoneType]=None, structured_layout:bool=False) ><a title="redvox.common.load_sensor_data.ReadResult" href="#redvox.common.load_sensor_data.ReadResult">ReadResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>load all data files in the directory
:param directory: location of all the files; if structured_layout is True, the directory contains a root api1000,
api900, or mseed directory, if structured_layout is False, the directory contains unsorted files
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:param redvox_ids: An optional list of redvox_ids to filter against, default empty list
:param structured_layout: An optional value to define if this is loading structured data, default False.
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_all_in_dir(directory: str,
                    start_timestamp_utc_s: Optional[int] = None,
                    end_timestamp_utc_s: Optional[int] = None,
                    redvox_ids: Optional[List[str]] = None,
                    structured_layout: bool = False) -&gt; ReadResult:
    &#34;&#34;&#34;
    load all data files in the directory
    :param directory: location of all the files; if structured_layout is True, the directory contains a root api1000,
                        api900, or mseed directory, if structured_layout is False, the directory contains unsorted files
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    # create the object to store the data
    stations: ReadResult = ReadResult({})
    # if structured_layout, there should be a specifically named folder in directory
    if structured_layout:
        if &#34;api900&#34; not in directory:
            api900_dir = os.path.join(directory, &#34;api900&#34;)
        else:
            api900_dir = directory
        if &#34;api1000&#34; not in directory:
            apim_dir = os.path.join(directory, &#34;api1000&#34;)
        else:
            apim_dir = directory
        if &#34;mseed&#34; not in directory:
            mseed_dir = os.path.join(directory, &#34;mseed&#34;)
        else:
            mseed_dir = directory
        # check if none of the paths exists
        if not (os.path.exists(api900_dir) or os.path.exists(apim_dir) or os.path.exists(mseed_dir)):
            # no specially named directory found; raise error
            raise ValueError(f&#34;{directory} does not contain api900, api1000 or mseed directory.&#34;)
    else:
        # load files from unstructured layout; everything is sitting in the main directory
        api900_dir = directory
        apim_dir = directory
        mseed_dir = directory

    # get api900 data
    stations.append(load_file_range_from_api900(api900_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                                redvox_ids, structured_layout, False))
    # get api1000 data
    stations.append(load_from_file_range_api_m(apim_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                               redvox_ids, structured_layout))
    # get mseed data
    all_paths = glob.glob(os.path.join(mseed_dir, &#34;*.mseed&#34;))
    for path in all_paths:
        stations.append(load_from_mseed(path, redvox_ids))
    return stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_api900_non_mic_sensor"><code class="name flex">
<span>def <span class="ident">read_api900_non_mic_sensor</span></span>(<span>sensor:typing.Union[<a title="redvox.api900.sensors.evenly_sampled_sensor.EvenlySampledSensor" href="../api900/sensors/evenly_sampled_sensor.html#redvox.api900.sensors.evenly_sampled_sensor.EvenlySampledSensor">EvenlySampledSensor</a>,<a title="redvox.api900.sensors.unevenly_sampled_sensor.UnevenlySampledSensor" href="../api900/sensors/unevenly_sampled_sensor.html#redvox.api900.sensors.unevenly_sampled_sensor.UnevenlySampledSensor">UnevenlySampledSensor</a>,<a title="redvox.api900.sensors.microphone_sensor.MicrophoneSensor" href="../api900/sensors/microphone_sensor.html#redvox.api900.sensors.microphone_sensor.MicrophoneSensor">MicrophoneSensor</a>,<a title="redvox.api900.sensors.barometer_sensor.BarometerSensor" href="../api900/sensors/barometer_sensor.html#redvox.api900.sensors.barometer_sensor.BarometerSensor">BarometerSensor</a>,<a title="redvox.api900.sensors.location_sensor.LocationSensor" href="../api900/sensors/location_sensor.html#redvox.api900.sensors.location_sensor.LocationSensor">LocationSensor</a>,<a title="redvox.api900.sensors.time_synchronization_sensor.TimeSynchronizationSensor" href="../api900/sensors/time_synchronization_sensor.html#redvox.api900.sensors.time_synchronization_sensor.TimeSynchronizationSensor">TimeSynchronizationSensor</a>,<a title="redvox.api900.sensors.accelerometer_sensor.AccelerometerSensor" href="../api900/sensors/accelerometer_sensor.html#redvox.api900.sensors.accelerometer_sensor.AccelerometerSensor">AccelerometerSensor</a>,<a title="redvox.api900.sensors.gyroscope_sensor.GyroscopeSensor" href="../api900/sensors/gyroscope_sensor.html#redvox.api900.sensors.gyroscope_sensor.GyroscopeSensor">GyroscopeSensor</a>,<a title="redvox.api900.sensors.magnetometer_sensor.MagnetometerSensor" href="../api900/sensors/magnetometer_sensor.html#redvox.api900.sensors.magnetometer_sensor.MagnetometerSensor">MagnetometerSensor</a>,<a title="redvox.api900.sensors.light_sensor.LightSensor" href="../api900/sensors/light_sensor.html#redvox.api900.sensors.light_sensor.LightSensor">LightSensor</a>,<a title="redvox.api900.sensors.infrared_sensor.InfraredSensor" href="../api900/sensors/infrared_sensor.html#redvox.api900.sensors.infrared_sensor.InfraredSensor">InfraredSensor</a>,<a title="redvox.api900.sensors.image_sensor.ImageSensor" href="../api900/sensors/image_sensor.html#redvox.api900.sensors.image_sensor.ImageSensor">ImageSensor</a>], column_id:str) ><a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a></span>
</code></dt>
<dd>
<div class="desc"><p>read a sensor that does not have mic data from an api900 data packet
:param sensor: the non-mic api900 sensor to read
:param column_id: string, used to name the columns
:return: generic SensorData object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_api900_non_mic_sensor(sensor: api900_io.RedvoxSensor, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that does not have mic data from an api900 data packet
    :param sensor: the non-mic api900 sensor to read
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.timestamps_microseconds_utc()
    if len(timestamps) &gt; 1:
        sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
    else:
        sample_interval = np.nan
    if type(sensor) in [api900_io.AccelerometerSensor, api900_io.MagnetometerSensor, api900_io.GyroscopeSensor]:
        data_for_df = np.transpose([timestamps,
                                    sensor.payload_values_x(), sensor.payload_values_y(), sensor.payload_values_z()])
        columns = [&#34;timestamps&#34;, f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    else:
        data_for_df = np.transpose([timestamps, sensor.payload_values()])
        columns = [&#34;timestamps&#34;, column_id]
    return SensorData(sensor.sensor_name(), pd.DataFrame(data_for_df, columns=columns), 1 / sample_interval,
                      sample_interval, False)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_api900_wrapped_packet"><code class="name flex">
<span>def <span class="ident">read_api900_wrapped_packet</span></span>(<span>wrapped_packet:<a title="redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket" href="../api900/wrapped_redvox_packet.html#redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket">WrappedRedvoxPacket</a>) >typing.Dict[<a title="redvox.common.sensor_data.SensorType" href="sensor_data.html#redvox.common.sensor_data.SensorType">SensorType</a>,<a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>reads the data from a wrapped api900 redvox packet into a dictionary of generic data
:param wrapped_packet: a wrapped api900 redvox packet
:return: a dictionary containing all the sensor data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_api900_wrapped_packet(wrapped_packet: api900_io.WrappedRedvoxPacket) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api900 redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api900 redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    data_dict: Dict[SensorType, SensorData] = {}
    # there are 9 api900 sensors
    if wrapped_packet.has_microphone_sensor():
        sample_rate_hz = wrapped_packet.microphone_sensor().sample_rate_hz()
        timestamps = calc_evenly_sampled_timestamps(
            wrapped_packet.microphone_sensor().first_sample_timestamp_epoch_microseconds_utc(),
            fs.get_num_points_from_sample_rate(sample_rate_hz), sample_rate_hz)
        data_for_df = np.transpose([timestamps, wrapped_packet.microphone_sensor().payload_values().astype(float)])
        data_dict[SensorType.AUDIO] = SensorData(wrapped_packet.microphone_sensor().sensor_name(),
                                                 pd.DataFrame(data_for_df, columns=[&#34;timestamps&#34;, &#34;microphone&#34;]),
                                                 sample_rate_hz, 1 / sample_rate_hz, True)
    if wrapped_packet.has_accelerometer_sensor():
        data_dict[SensorType.ACCELEROMETER] = \
            read_api900_non_mic_sensor(wrapped_packet.accelerometer_sensor(), &#34;accelerometer&#34;)
    if wrapped_packet.has_magnetometer_sensor():
        data_dict[SensorType.MAGNETOMETER] = \
            read_api900_non_mic_sensor(wrapped_packet.magnetometer_sensor(), &#34;magnetometer&#34;)
    if wrapped_packet.has_gyroscope_sensor():
        data_dict[SensorType.GYROSCOPE] = read_api900_non_mic_sensor(wrapped_packet.gyroscope_sensor(), &#34;gyroscope&#34;)
    if wrapped_packet.has_barometer_sensor():
        data_dict[SensorType.PRESSURE] = read_api900_non_mic_sensor(wrapped_packet.barometer_sensor(), &#34;barometer&#34;)
    if wrapped_packet.has_light_sensor():
        data_dict[SensorType.LIGHT] = read_api900_non_mic_sensor(wrapped_packet.light_sensor(), &#34;light&#34;)
    if wrapped_packet.has_infrared_sensor():
        data_dict[SensorType.INFRARED] = read_api900_non_mic_sensor(wrapped_packet.infrared_sensor(), &#34;infrared&#34;)
    if wrapped_packet.has_image_sensor():
        data_dict[SensorType.IMAGE] = read_api900_non_mic_sensor(wrapped_packet.image_sensor(), &#34;image&#34;)
    if wrapped_packet.has_location_sensor():
        timestamps = wrapped_packet.location_sensor().timestamps_microseconds_utc()
        if len(timestamps) &gt; 1:
            sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
        else:
            sample_interval = np.nan
        if wrapped_packet.location_sensor().check_for_preset_lat_lon():
            lat_lon = wrapped_packet.location_sensor().get_payload_lat_lon()
            data_for_df = np.array([[timestamps[0], lat_lon[0], lat_lon[1], np.nan, np.nan, np.nan,
                                     LocationProvider.USER]])
        else:
            data_for_df = np.transpose([timestamps,
                                        wrapped_packet.location_sensor().payload_values_latitude(),
                                        wrapped_packet.location_sensor().payload_values_longitude(),
                                        wrapped_packet.location_sensor().payload_values_altitude(),
                                        wrapped_packet.location_sensor().payload_values_speed(),
                                        wrapped_packet.location_sensor().payload_values_accuracy(),
                                        np.full(len(timestamps), np.nan)])
        columns = [&#34;timestamps&#34;, &#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;accuracy&#34;, &#34;location_provider&#34;]
        data_dict[SensorType.LOCATION] = SensorData(wrapped_packet.location_sensor().sensor_name(),
                                                    pd.DataFrame(data_for_df, columns=columns),
                                                    1 / sample_interval, sample_interval, False)
    return data_dict</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_apim_single_sensor"><code class="name flex">
<span>def <span class="ident">read_apim_single_sensor</span></span>(<span>sensor:<a title="redvox.api1000.wrapped_redvox_packet.sensors.single.Single" href="../api1000/wrapped_redvox_packet/sensors/single.html#redvox.api1000.wrapped_redvox_packet.sensors.single.Single">Single</a>, column_id:str) ><a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a></span>
</code></dt>
<dd>
<div class="desc"><p>read a sensor that has a single data channel from an api M data packet
:param sensor: the single channel api M sensor to read
:param column_id: string, used to name the columns
:return: generic SensorData object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_apim_single_sensor(sensor: single.Single, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has a single data channel from an api M data packet
    :param sensor: the single channel api M sensor to read
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    if len(timestamps) &gt; 1:
        sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
    else:
        sample_interval = np.nan
    data_for_df = np.transpose([timestamps, sensor.get_samples().get_values()])
    columns = [&#34;timestamps&#34;, column_id]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, columns=columns),
                      sample_interval, sample_interval, False)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_apim_xyz_sensor"><code class="name flex">
<span>def <span class="ident">read_apim_xyz_sensor</span></span>(<span>sensor:<a title="redvox.api1000.wrapped_redvox_packet.sensors.xyz.Xyz" href="../api1000/wrapped_redvox_packet/sensors/xyz.html#redvox.api1000.wrapped_redvox_packet.sensors.xyz.Xyz">Xyz</a>, column_id:str) ><a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a></span>
</code></dt>
<dd>
<div class="desc"><p>read a sensor that has xyz data channels from an api M data packet
:param sensor: the xyz api M sensor to read
:param column_id: string, used to name the columns
:return: generic SensorData object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_apim_xyz_sensor(sensor: xyz.Xyz, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has xyz data channels from an api M data packet
    :param sensor: the xyz api M sensor to read
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    if len(timestamps) &gt; 1:
        sample_interval = dtu.microseconds_to_seconds(float(np.mean(np.diff(timestamps))))
    else:
        sample_interval = np.nan
    data_for_df = np.transpose([timestamps,
                                sensor.get_x_samples().get_values(),
                                sensor.get_y_samples().get_values(),
                                sensor.get_z_samples().get_values()])
    columns = [&#34;timestamps&#34;, f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, columns=columns),
                      1 / sample_interval, sample_interval, False)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="redvox.common.load_sensor_data.ReadResult"><code class="flex name class">
<span>class <span class="ident">ReadResult</span></span>
<span>(</span><span>station_id_uuid_to_stations:typing.Dict[str,<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>])</span>
</code></dt>
<dd>
<div class="desc"><p>Stores station information after being read from files</p>
<p>:param station_id_uuid_to_stations: station_id:station_uuid -&gt; station information</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ReadResult:
    &#34;&#34;&#34;
    Stores station information after being read from files
    &#34;&#34;&#34;
    def __init__(self,
                 station_id_uuid_to_stations: Dict[str, Station]):
        &#34;&#34;&#34;
        :param station_id_uuid_to_stations: station_id:station_uuid -&gt; station information
        &#34;&#34;&#34;
        self.station_id_uuid_to_stations: Dict[str, Station] = station_id_uuid_to_stations
        self.__station_id_to_id_uuid: Dict[str, str] = {}
        self.__station_summaries: List[StationSummary] = []

        self.update_metadata()

    def update_metadata(self):
        &#34;&#34;&#34;
        updates ids:uuids pairs and summary information
        &#34;&#34;&#34;
        for id_uuid, station in self.station_id_uuid_to_stations.items():
            s: List[str] = id_uuid.split(&#34;:&#34;)
            self.__station_id_to_id_uuid[s[0]] = s[1]
            self.__station_summaries.append(StationSummary.from_station(station))

    def __get_station_id_by_uuid(self, uuid: str) -&gt; str:
        &#34;&#34;&#34;
        given a uuid, returns the station_id
        :param uuid: uuid to search for
        :return: the station_id of the uuid, or an empty string if uuid doesn&#39;t exist
        &#34;&#34;&#34;
        for station_id, station_uuid in self.__station_id_to_id_uuid.items():
            if station_uuid == uuid:
                return station_id
        return &#34;&#34;

    def pop_station(self, station_id: str) -&gt; &#39;ReadResult&#39;:
        &#34;&#34;&#34;
        removes a station from the ReadResult; station_id can be one of id, uuid or id:uuid
        :param station_id: station to remove
        :return: copy of ReadResult without the station_id specified
        &#34;&#34;&#34;
        if &#34;:&#34; in station_id:
            s: List[str] = station_id.split(&#34;:&#34;)
            station_id = s[0]
        elif station_id in self.__station_id_to_id_uuid.values():  # check if uuid was given
            station_id = self.__get_station_id_by_uuid(station_id)
        if self.check_for_id(station_id):
            self.station_id_uuid_to_stations.pop(f&#34;{station_id}:{self.__station_id_to_id_uuid[station_id]}&#34;)
            self.__station_id_to_id_uuid.pop(station_id)
            summaries = self.__station_summaries.copy()  # put summaries into temp variable
            self.__station_summaries.clear()             # clear summaries and rebuild
            for summary in summaries:
                if summary.station_id != station_id:
                    self.__station_summaries.append(summary)
        else:
            print(f&#34;ReadResult cannot remove station {station_id} because it does not exist&#34;)
        return self

    def check_for_id(self, check_id: str) -&gt; bool:
        &#34;&#34;&#34;
        Look at keys and shortened keys in for the check_id; must be id or uuid combination
        :param check_id: id to look for
        :return: True if check_id is in the ReadResult
        &#34;&#34;&#34;
        return check_id in self.__station_id_to_id_uuid.keys() or check_id in self.__station_id_to_id_uuid.values()

    def get_station(self, station_id: str) -&gt; Optional[Station]:
        &#34;&#34;&#34;
        Find the station identified by the station_id given; it can be id or id:uuid
        :param station_id: str id of station; can be id or id:uuid
        :return: the station if it exists, None otherwise
        &#34;&#34;&#34;
        if &#34;:&#34; in station_id:
            return self.station_id_uuid_to_stations[station_id]
        elif self.check_for_id(station_id):
            return self.station_id_uuid_to_stations[f&#34;{station_id}:{self.__station_id_to_id_uuid[station_id]}&#34;]
        print(f&#34;WARNING: ReadResult attempted to read station id: {station_id}, but could not find id in results&#34;)
        return None

    def get_all_stations(self) -&gt; List[Station]:
        &#34;&#34;&#34;
        Return a list of all stations in the ReadResult
        :return: a list of all stations
        &#34;&#34;&#34;
        return list(self.station_id_uuid_to_stations.values())

    def get_station_summaries(self) -&gt; List[StationSummary]:
        &#34;&#34;&#34;
        :return: A list of StationSummaries contained in this ReadResult
        &#34;&#34;&#34;
        return self.__station_summaries

    def append_station(self, new_station_id: str, new_station: Station):
        &#34;&#34;&#34;
        adds a station to the ReadResult.  Appends data to existing stations
        :param new_station_id: id of station to add
        :param new_station: Station object to add
        &#34;&#34;&#34;
        if self.check_for_id(new_station_id):
            self.station_id_uuid_to_stations[new_station_id].append_station_data(new_station.station_data)
        else:
            self.station_id_uuid_to_stations[new_station_id] = new_station
            self.__station_id_to_id_uuid[new_station.station_metadata.station_id] = \
                new_station.station_metadata.station_uuid
            self.__station_summaries.append(StationSummary.from_station(new_station))

    def append(self, new_stations: &#39;ReadResult&#39;):
        &#34;&#34;&#34;
        adds stations to the ReadResult
        :param new_stations: stations to add
        &#34;&#34;&#34;
        for new_station_id, new_station in new_stations.station_id_uuid_to_stations.items():
            self.append_station(new_station_id, new_station)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="redvox.common.load_sensor_data.ReadResult.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, new_stations:<a title="redvox.common.load_sensor_data.ReadResult" href="#redvox.common.load_sensor_data.ReadResult">ReadResult</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>adds stations to the ReadResult
:param new_stations: stations to add</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append(self, new_stations: &#39;ReadResult&#39;):
    &#34;&#34;&#34;
    adds stations to the ReadResult
    :param new_stations: stations to add
    &#34;&#34;&#34;
    for new_station_id, new_station in new_stations.station_id_uuid_to_stations.items():
        self.append_station(new_station_id, new_station)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.ReadResult.append_station"><code class="name flex">
<span>def <span class="ident">append_station</span></span>(<span>self, new_station_id:str, new_station:<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>adds a station to the ReadResult.
Appends data to existing stations
:param new_station_id: id of station to add
:param new_station: Station object to add</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append_station(self, new_station_id: str, new_station: Station):
    &#34;&#34;&#34;
    adds a station to the ReadResult.  Appends data to existing stations
    :param new_station_id: id of station to add
    :param new_station: Station object to add
    &#34;&#34;&#34;
    if self.check_for_id(new_station_id):
        self.station_id_uuid_to_stations[new_station_id].append_station_data(new_station.station_data)
    else:
        self.station_id_uuid_to_stations[new_station_id] = new_station
        self.__station_id_to_id_uuid[new_station.station_metadata.station_id] = \
            new_station.station_metadata.station_uuid
        self.__station_summaries.append(StationSummary.from_station(new_station))</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.ReadResult.check_for_id"><code class="name flex">
<span>def <span class="ident">check_for_id</span></span>(<span>self, check_id:str) >bool</span>
</code></dt>
<dd>
<div class="desc"><p>Look at keys and shortened keys in for the check_id; must be id or uuid combination
:param check_id: id to look for
:return: True if check_id is in the ReadResult</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_for_id(self, check_id: str) -&gt; bool:
    &#34;&#34;&#34;
    Look at keys and shortened keys in for the check_id; must be id or uuid combination
    :param check_id: id to look for
    :return: True if check_id is in the ReadResult
    &#34;&#34;&#34;
    return check_id in self.__station_id_to_id_uuid.keys() or check_id in self.__station_id_to_id_uuid.values()</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.ReadResult.get_all_stations"><code class="name flex">
<span>def <span class="ident">get_all_stations</span></span>(<span>self) >typing.List[<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Return a list of all stations in the ReadResult
:return: a list of all stations</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_stations(self) -&gt; List[Station]:
    &#34;&#34;&#34;
    Return a list of all stations in the ReadResult
    :return: a list of all stations
    &#34;&#34;&#34;
    return list(self.station_id_uuid_to_stations.values())</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.ReadResult.get_station"><code class="name flex">
<span>def <span class="ident">get_station</span></span>(<span>self, station_id:str) >typing.Union[<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>,NoneType]</span>
</code></dt>
<dd>
<div class="desc"><p>Find the station identified by the station_id given; it can be id or id:uuid
:param station_id: str id of station; can be id or id:uuid
:return: the station if it exists, None otherwise</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_station(self, station_id: str) -&gt; Optional[Station]:
    &#34;&#34;&#34;
    Find the station identified by the station_id given; it can be id or id:uuid
    :param station_id: str id of station; can be id or id:uuid
    :return: the station if it exists, None otherwise
    &#34;&#34;&#34;
    if &#34;:&#34; in station_id:
        return self.station_id_uuid_to_stations[station_id]
    elif self.check_for_id(station_id):
        return self.station_id_uuid_to_stations[f&#34;{station_id}:{self.__station_id_to_id_uuid[station_id]}&#34;]
    print(f&#34;WARNING: ReadResult attempted to read station id: {station_id}, but could not find id in results&#34;)
    return None</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.ReadResult.get_station_summaries"><code class="name flex">
<span>def <span class="ident">get_station_summaries</span></span>(<span>self) >typing.List[<a title="redvox.common.load_sensor_data.StationSummary" href="#redvox.common.load_sensor_data.StationSummary">StationSummary</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>:return: A list of StationSummaries contained in this ReadResult</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_station_summaries(self) -&gt; List[StationSummary]:
    &#34;&#34;&#34;
    :return: A list of StationSummaries contained in this ReadResult
    &#34;&#34;&#34;
    return self.__station_summaries</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.ReadResult.pop_station"><code class="name flex">
<span>def <span class="ident">pop_station</span></span>(<span>self, station_id:str) ><a title="redvox.common.load_sensor_data.ReadResult" href="#redvox.common.load_sensor_data.ReadResult">ReadResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>removes a station from the ReadResult; station_id can be one of id, uuid or id:uuid
:param station_id: station to remove
:return: copy of ReadResult without the station_id specified</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pop_station(self, station_id: str) -&gt; &#39;ReadResult&#39;:
    &#34;&#34;&#34;
    removes a station from the ReadResult; station_id can be one of id, uuid or id:uuid
    :param station_id: station to remove
    :return: copy of ReadResult without the station_id specified
    &#34;&#34;&#34;
    if &#34;:&#34; in station_id:
        s: List[str] = station_id.split(&#34;:&#34;)
        station_id = s[0]
    elif station_id in self.__station_id_to_id_uuid.values():  # check if uuid was given
        station_id = self.__get_station_id_by_uuid(station_id)
    if self.check_for_id(station_id):
        self.station_id_uuid_to_stations.pop(f&#34;{station_id}:{self.__station_id_to_id_uuid[station_id]}&#34;)
        self.__station_id_to_id_uuid.pop(station_id)
        summaries = self.__station_summaries.copy()  # put summaries into temp variable
        self.__station_summaries.clear()             # clear summaries and rebuild
        for summary in summaries:
            if summary.station_id != station_id:
                self.__station_summaries.append(summary)
    else:
        print(f&#34;ReadResult cannot remove station {station_id} because it does not exist&#34;)
    return self</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.ReadResult.update_metadata"><code class="name flex">
<span>def <span class="ident">update_metadata</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>updates ids:uuids pairs and summary information</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_metadata(self):
    &#34;&#34;&#34;
    updates ids:uuids pairs and summary information
    &#34;&#34;&#34;
    for id_uuid, station in self.station_id_uuid_to_stations.items():
        s: List[str] = id_uuid.split(&#34;:&#34;)
        self.__station_id_to_id_uuid[s[0]] = s[1]
        self.__station_summaries.append(StationSummary.from_station(station))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary"><code class="flex name class">
<span>class <span class="ident">StationSummary</span></span>
<span>(</span><span>station_id:str, station_uuid:str, os:str, os_version:str, app_version:str, audio_sampling_rate:float, total_duration:float, start_dt:datetime.datetime, end_dt:datetime.datetime)</span>
</code></dt>
<dd>
<div class="desc"><p>Contains a summary of each stations data read result.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StationSummary:
    &#34;&#34;&#34;
    Contains a summary of each stations data read result.
    &#34;&#34;&#34;
    station_id: str
    station_uuid: str
    os: str
    os_version: str
    app_version: str
    audio_sampling_rate: float
    total_duration: float
    start_dt: dtu.datetime
    end_dt: dtu.datetime

    @staticmethod
    def from_station(station: Station) -&gt; &#39;StationSummary&#39;:
        total_duration: float = station.audio_sensor().data_duration_s()
        start_dt: dtu.datetime = dtu.datetime_from_epoch_microseconds_utc(station.audio_sensor().first_data_timestamp())
        end_dt: dtu.datetime = dtu.datetime_from_epoch_microseconds_utc(station.audio_sensor().last_data_timestamp())

        station_info = station.station_metadata
        audio = station.audio_sensor()
        return StationSummary(
            station_info.station_id,
            station_info.station_uuid,
            station_info.station_os if station_info.station_os is not None else &#34;OS UNKNOWN&#34;,
            station_info.station_os_version if station_info.station_os_version is not None else &#34;OS VERSION UNKNOWN&#34;,
            station_info.station_app_version if station_info.station_app_version is not None else &#34;APP VERSION UNKNOWN&#34;,
            audio.sample_rate if audio is not None else float(&#34;NaN&#34;),
            total_duration,
            start_dt,
            end_dt
        )</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="redvox.common.load_sensor_data.StationSummary.app_version"><code class="name">var <span class="ident">app_version</span> :str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.audio_sampling_rate"><code class="name">var <span class="ident">audio_sampling_rate</span> :float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.end_dt"><code class="name">var <span class="ident">end_dt</span> :datetime.datetime</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.os"><code class="name">var <span class="ident">os</span> :str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.os_version"><code class="name">var <span class="ident">os_version</span> :str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.start_dt"><code class="name">var <span class="ident">start_dt</span> :datetime.datetime</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.station_id"><code class="name">var <span class="ident">station_id</span> :str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.station_uuid"><code class="name">var <span class="ident">station_uuid</span> :str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.load_sensor_data.StationSummary.total_duration"><code class="name">var <span class="ident">total_duration</span> :float</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="redvox.common.load_sensor_data.StationSummary.from_station"><code class="name flex">
<span>def <span class="ident">from_station</span></span>(<span>station:<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>) ><a title="redvox.common.load_sensor_data.StationSummary" href="#redvox.common.load_sensor_data.StationSummary">StationSummary</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_station(station: Station) -&gt; &#39;StationSummary&#39;:
    total_duration: float = station.audio_sensor().data_duration_s()
    start_dt: dtu.datetime = dtu.datetime_from_epoch_microseconds_utc(station.audio_sensor().first_data_timestamp())
    end_dt: dtu.datetime = dtu.datetime_from_epoch_microseconds_utc(station.audio_sensor().last_data_timestamp())

    station_info = station.station_metadata
    audio = station.audio_sensor()
    return StationSummary(
        station_info.station_id,
        station_info.station_uuid,
        station_info.station_os if station_info.station_os is not None else &#34;OS UNKNOWN&#34;,
        station_info.station_os_version if station_info.station_os_version is not None else &#34;OS VERSION UNKNOWN&#34;,
        station_info.station_app_version if station_info.station_app_version is not None else &#34;APP VERSION UNKNOWN&#34;,
        audio.sample_rate if audio is not None else float(&#34;NaN&#34;),
        total_duration,
        start_dt,
        end_dt
    )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="redvox.common" href="index.html">redvox.common</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="redvox.common.load_sensor_data.calc_evenly_sampled_timestamps" href="#redvox.common.load_sensor_data.calc_evenly_sampled_timestamps">calc_evenly_sampled_timestamps</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_apim_wrapped_packet" href="#redvox.common.load_sensor_data.load_apim_wrapped_packet">load_apim_wrapped_packet</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_file_range_from_api900" href="#redvox.common.load_sensor_data.load_file_range_from_api900">load_file_range_from_api900</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_from_file_range_api_m" href="#redvox.common.load_sensor_data.load_from_file_range_api_m">load_from_file_range_api_m</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_from_mseed" href="#redvox.common.load_sensor_data.load_from_mseed">load_from_mseed</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_station_from_api900" href="#redvox.common.load_sensor_data.load_station_from_api900">load_station_from_api900</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_station_from_api900_file" href="#redvox.common.load_sensor_data.load_station_from_api900_file">load_station_from_api900_file</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_station_from_apim" href="#redvox.common.load_sensor_data.load_station_from_apim">load_station_from_apim</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_all_in_dir" href="#redvox.common.load_sensor_data.read_all_in_dir">read_all_in_dir</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_api900_non_mic_sensor" href="#redvox.common.load_sensor_data.read_api900_non_mic_sensor">read_api900_non_mic_sensor</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_api900_wrapped_packet" href="#redvox.common.load_sensor_data.read_api900_wrapped_packet">read_api900_wrapped_packet</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_apim_single_sensor" href="#redvox.common.load_sensor_data.read_apim_single_sensor">read_apim_single_sensor</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_apim_xyz_sensor" href="#redvox.common.load_sensor_data.read_apim_xyz_sensor">read_apim_xyz_sensor</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="redvox.common.load_sensor_data.ReadResult" href="#redvox.common.load_sensor_data.ReadResult">ReadResult</a></code></h4>
<ul class="">
<li><code><a title="redvox.common.load_sensor_data.ReadResult.append" href="#redvox.common.load_sensor_data.ReadResult.append">append</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.ReadResult.append_station" href="#redvox.common.load_sensor_data.ReadResult.append_station">append_station</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.ReadResult.check_for_id" href="#redvox.common.load_sensor_data.ReadResult.check_for_id">check_for_id</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.ReadResult.get_all_stations" href="#redvox.common.load_sensor_data.ReadResult.get_all_stations">get_all_stations</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.ReadResult.get_station" href="#redvox.common.load_sensor_data.ReadResult.get_station">get_station</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.ReadResult.get_station_summaries" href="#redvox.common.load_sensor_data.ReadResult.get_station_summaries">get_station_summaries</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.ReadResult.pop_station" href="#redvox.common.load_sensor_data.ReadResult.pop_station">pop_station</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.ReadResult.update_metadata" href="#redvox.common.load_sensor_data.ReadResult.update_metadata">update_metadata</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="redvox.common.load_sensor_data.StationSummary" href="#redvox.common.load_sensor_data.StationSummary">StationSummary</a></code></h4>
<ul class="two-column">
<li><code><a title="redvox.common.load_sensor_data.StationSummary.app_version" href="#redvox.common.load_sensor_data.StationSummary.app_version">app_version</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.audio_sampling_rate" href="#redvox.common.load_sensor_data.StationSummary.audio_sampling_rate">audio_sampling_rate</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.end_dt" href="#redvox.common.load_sensor_data.StationSummary.end_dt">end_dt</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.from_station" href="#redvox.common.load_sensor_data.StationSummary.from_station">from_station</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.os" href="#redvox.common.load_sensor_data.StationSummary.os">os</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.os_version" href="#redvox.common.load_sensor_data.StationSummary.os_version">os_version</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.start_dt" href="#redvox.common.load_sensor_data.StationSummary.start_dt">start_dt</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.station_id" href="#redvox.common.load_sensor_data.StationSummary.station_id">station_id</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.station_uuid" href="#redvox.common.load_sensor_data.StationSummary.station_uuid">station_uuid</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.StationSummary.total_duration" href="#redvox.common.load_sensor_data.StationSummary.total_duration">total_duration</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>